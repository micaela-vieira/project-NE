Title: Der lange Weg zu Open Science
Author: Sven Titz
Abstract: Viele Forscher finden die neue Wissenschaftskultur gut, zögern aber noch, sich auf offenen Erkenntnisaustausch einzulassen. Mangelnde Kenntnisse im Datenmanagement und die Angst vor Ideenklau sind nur zwei der vielen Gründe.

Transparenter und kollaborativer: Die Forschung muss sich neu erfinden. Aber wie?
Wissenschaftler legen von Beginn an ihre Studien- und Versuchspläne offen; sie berichten auf Blogs transparent und tagesaktuell über ihre Fortschritte im Labor; später publizieren sie in Open-Access-Zeitschriften, die per Open Peer Review begutachtet wurden. Die Resultate legen sie in für alle Welt einsehbare Datenbanken nieder. Soweit die Utopie der Open Science.
Kommt jetzt die gläserne Forschung? Ganz so einfach entwickeln sich die Dinge wohl nicht. Denn manchmal fehlt das liebe Geld. Manchmal ist niemand in der Lage, eine erforderliche Datenbank anzulegen. Oder Wissenschaftler zögern, ihre Daten offenzulegen, weil sie fürchten, die Konkurrenz könnte die Idee klauen und schneller publizieren.
Unterschätzter Aufwand
Die Erfolge mit der Offenlegung von Forschungsdaten, die Big Science vorzuweisen vermag – sei es am Kernforschungszentrum Cern, sei es in der Genforschung –, können täuschen. In vielen Bereichen ausserhalb von Grossprojekten bestehen noch starke Hemmnisse. Die Freigabe von Daten zu fordern ist leicht. Doch einzelne Forscher, die nicht die Mittel und Expertise haben, verzweifeln an der Aufgabe. Da Einzelforscher und kleine Gruppen Schwierigkeiten mit der Offenlegung haben, können ihre Daten oft nicht oder nur schwer von anderen Wissenschaftlern genutzt werden. "Vielen fehlt die Zeit und die Kenntnis, um die Daten ausreichend zu dokumentieren und bereitzustellen", sagt Benedikt Fecher. Der Doktorand am Deutschen Institut für Wirtschaftsforschung sowie am Alexander von Humboldt Institut für Internet und Gesellschaft in Berlin hat die Einstellung der Forscher zu Open Science erkundet.
In den USA und in Europa haben sich die Organisationen zur Forschungsförderung auf die Fahnen geschrieben, die Offenlegung von Daten voranzutreiben. Dazu genügt es aber nicht, Open-Science-Standards zu diktieren. Forscher benötigen auch organisatorische, finanzielle und personelle Unterstützung – wie sie zum Beispiel das Schweizer Kompetenzzentrum Sozialwissenschaften (FORS) leistet. Die Institution hilft bei der Aufbereitung, Dokumentation und Speicherung sozialwissenschaftlicher Forschungsdaten und stellt die nötige Infrastruktur zur Verfügung. Wissenschaftler können sich zum Beispiel in Workshops weiterbilden und für das Datenmanagement auf Online-Tools zugreifen.
In den Naturwissenschaften ist Open Data schon etabliert, doch Sozialwissenschaftler fremdeln noch mit dem Konzept. Das liegt zwar auch daran, dass sie meistens mit personenbezogenen Daten arbeiten, die dem Datenschutz unterliegen – aber nicht nur. Generell seien Sozialwissenschaftler oft nicht daran gewöhnt, Daten standardisiert zu dokumentieren, benennt Alexandra Stam, Leiterin der FORS-Gruppe "Data Promotion", eines der Probleme: "Viele Forscher realisieren nicht, dass ihre Daten nach der eigentlichen Arbeit weiterleben können." Auf diese Weise gingen viele potenziell wertvolle Daten und wichtige Details unnötigerweise verloren.
Die Ursachen für die Misere liegen unter anderem in der Ausbildung. Datenmanagement werde im Studium nicht formal gelehrt, sagt die Expertin. Oft würden Forscher es verpassen, die Daten bereits während des Projekts zu dokumentieren. Stattdessen fingen sie erst damit an, wenn sich das Vorhaben dem Ende zuneige.
In manchen Ländern, etwa in den USA und im Vereinigten Königreich, muss ein Plan zum Datenmanagement oft schon mit dem Antrag zur Forschungsförderung erstellt werden. In der Schweiz ist das noch nicht der Fall. Stam hofft, dies werde bald kommen. Darüber hinaus hat es sich als essenziell erwiesen, einmal dokumentierte und offengelegte Daten in dauerhaften Datenbanken zu speichern. Sonst hängt deren Pflege nach Ablauf eines Projekts in der Luft.
Die Online­ Wandtafel: Mathematiker wie Emmanuel Kowalski von der ETH Zürich legen Probleme vor, diskutieren sie und lösen sie gemeinsam. Das Projekt Polymath funktioniert wie ein Blog: Es ist offen für alle und nährt sich von der Diskussion in Form von Kommentaren. Statt ihre Forschungsprojekte geheim zu halten, bündeln die Forscher spontan ihre Kräfte. | Bild: Valérie Chételat
Prinzipiell ja, aber …
Zu viel Optimismus ist bei Open Data bisher unangebracht – trotz institutioneller Hilfestellung wie durch das FORS. Selbst wenn die Forscher nicht mit der Aufgabe allein gelassen werden, zögern nicht wenige, ihre Daten offenzulegen. Fecher hat in seinen Befragungen in Forscherkreisen eine Diskrepanz festgestellt zwischen einer allgemein positiven Einstellung zu Open Science und der persönlichen Zurückhaltung, eigene Daten freizugeben.
Oft hemmt die Angst vor Ideendiebstahl die Forscher. Das Risiko mag stark überschätzt werden, doch dass solche Fälle gelegentlich auftreten, ist nicht von der Hand zu weisen. Der Genforscher Titus Brown an der University of California in Davis hat einmal berichtet, Konkurrenten hätten seine offengelegten Methoden für Fachartikel verwendet, die er selbst hätte schreiben können. Er ist trotzdem ein Verfechter der Offenlegung geblieben. Brown ist davon überzeugt, dass sie der Forschung nützt.
Natürlich gibt es noch weitere Ursachen für die Zurückhaltung. Der gepriesenen Transparenz kann zum Beispiel auch eine Art Gewohnheitsrecht im Weg stehen. In der empirischen Medizinforschung sei bis heute die "antiquierte" Haltung verbreitet, dass man als Urheber von Daten auch Koautor neuerer Studien werden müsse, wenn sich diese auf die eigenen Daten stützten, sagt Fecher.
Es fehlen Anreize
Generell, das beklagen viele Beobachter, mangelt es noch an Anreizen, Daten offenzulegen. Forscher werden heute an Qualität und Quantität ihrer Publikationen gemessen. Aber für Datensätze fehlt noch eine entsprechende akademische Anerkennung. "Die Forscher fänden das gut", sagt Doktorand Fecher. Auch Stam betont die Bedeutung dieses Anreizes: "Es ist wichtig, dass die Leute den Nutzen guten Datenmanagements für ihre eigene Forschung erkennen – jenseits des Datenteilens."
Immerhin sind in den vergangenen Jahren viele so genannte Datenjournale entstanden, die neue Datensätze ins Zentrum der Artikelpublikation stellen. Das bekannteste dürfte "Scientific Data" der Nature Publishing Group sein. Auch Archäologie, Geowissenschaften, Chemie und andere Wissenschaftszweige nutzen inzwischen fachspezifische Datenjournale. Diese spezialisierten Medien werden so lange eine Lücke füllen, bis Forschungsdaten formal anerkannt werden.
Die frivole Offenheit der Notizbücher
Ein bisschen anders liegen die Dinge bei der Offenlegung des Forschungsprozesses selbst, zum Beispiel in offenen "Labor-Notizbüchern". Der Ökosystemforscher Carl Boettiger von der University of California in Berkeley begann schon als Doktorand damit, seine Forschungsnotizen online zu stellen. Wie er heute sagt, hatte er einfach Glück: Er sei naiv an die Sache herangegangen; kein Vorgesetzter nahm Anstoss an seinem Notizbuch. Das ist aber nicht der Regelfall. Mit allzu ungestümer Offenheit irritieren manche Nachwuchsforscher ihre Kollegen. In manchen Situationen schaden sie sogar ihrer Karriere.
Boettiger nutzt das Notizbuch vor allem als Gedächtnisstütze und zum Austausch mit Kollegen, die er gezielt auf Einträge verweisen kann. Hin und wieder hätten ihn Koautoren von Fachartikeln gebeten, sensible Informationen zeitweise zurückzuhalten. Sonst aber schreibe er immer alles sofort auf. Ideen wurden ihm aufgrund des offenen Notizbuchs noch nicht geklaut. Neben vielen diffusen Sorgen wegen Open Science besteht ein reales Problem darin, dass die offenen Labor-Notizbücher Zeitfresser sein können. Laut Boettiger muss man sich je nach Computerkenntnissen in spezielle Programme einarbeiten. Da es dem Ökosystemforscher generell am Herzen liegt, Open Science in all ihren Facetten zu vereinfachen, hat er vor ein paar Jahren das Projekt "rOpenSci" mitbegründet – eine Plattform zur Bereitstellung von Software, mit der wissenschaftliche Daten aufbereitet und offengelegt werden und die auch für Labor-Notizbücher nützlich ist.
Pergament 2.0: Historische Manuskripte digitalisieren, damit Forschende aus aller Welt diese studieren können, ist gut. Noch besser ist es, sie aus Distanz gemeinsam zu kommentieren. An der Universität Bern erfasst die Historikerin Tara Andrews ihre Annotationen mit dem Instrument T-Pen und teilt sie online. | Bild: Valérie Chételat
Wenn Firmen bei der Hardware zögern
Selbstverständlich ist Open Science nicht auf Daten und Kommunikation beschränkt. In Open-Source-Projekten sind auch Hardware und Software transparent. Die Schaltpläne und Baupläne werden zur Verfügung gestellt – analog zum Quellcode bei Open-Source-Software, erläutert Lorenz Meier, Doktorand am Institute for Visual Computing der ETH Zürich. Meier hat in mehreren Projekten mit Firmen zusammengearbeitet. Meistens konnte er durchsetzen, mit offener Hard- und Software zu arbeiten. Das bedeutet bei Open-Source-Software, dass die Firmen oft bereit waren, auch die Verbesserungen weiterzugeben, die während eines Projekts erarbeitet wurden.
Zusammen mit Kollegen hat Meier zum Beispiel die Autopilot-Software "PX4" entwickelt, mit der sich Drohnen und Miniaturflugzeuge steuern lassen. Die Software und Anleitungen zur Hardware werden zum freien Download angeboten. Alles andere ergibt keinen Sinn, findet Meier. "Bei Drohnen sind Open-Source-Lösungen sogar militärischer Software überlegen." Kein Unternehmen sei mehr in der Lage, eine Neuentwicklung besserer Software selbst zu stemmen.
Die Zusammenarbeit mit Firmen klappt gut, findet Meier, wenn auch nicht immer auf Anhieb. Nach seiner Erfahrung sperren sich Firmen besonders dann gegen eine Offenlegung, wenn sie sich Probleme einbilden – zum Beispiel wenn sie ihr Geschäftsmodell bedroht sehen. Um solche Widerstände zu entkräften, müsse geklärt werden, woran sich bei einem Projekt überhaupt Geld verdienen lasse, sagt Meier. Und das ist eben oft weder der Bauplan noch die Software, sondern eher das Angebot von Expertise und Service.
Modelle wie Linux, bei denen der Quellcode offen zugänglich ist und keinen Schutz geniesst, hätten sich auf dem Markt bewährt, bestätigt Oliver Gassmann vom Institut für Technologiemanagement der Universität St. Gallen. Firmen hätten so grosse Vorteile erkannt, dass sie manchmal sogar Patente an die Open-Source-Bewegung spendeten. "Dann setzen sich nämlich neue Standards viel rascher durch als bei geschützten Lösungen", so Gassmann. In solchen Fällen besteht die Aufgabe der Unternehmen darin, die Wertschöpfung anderswo zu suchen.
Grundsätzlich beurteilt Gassmann die Zusammenarbeit von Forschungsinstituten mit Privatunternehmen positiv: Die Unternehmen erhielten Zugang zu Grundlagenwissen und die Forscher eine zusätzliche Finanzierung. Open Science könne dabei Konflikte verursachen, wenn Veröffentlichungen der Forscher so früh kommen, dass sie mit dem Stand der Technik bei den Patentanmeldungen kollidieren. Das sei aber ein grundsätzliches Problem, das auch in klassischen Kooperationsprojekten zwischen Hochschulen und Wirtschaftspartnern auftrete, meint Gassmann. Bei Open Science werde das Problem bloss verschärft.
Der lange Weg zu Open Science: Mathematiker wie Emmanuel Kowalski von der ETH Zürich legen Probleme vor, diskutieren sie und lösen sie gemeinsam. Das Projekt Polymath funktioniert wie ein Blog: Es ist offen für alle und nährt sich von der Diskussion in Form von Kommentaren. Statt ihre Forschungsprojekte geheim zu halten, bündeln die Forscher spontan ihre Kräfte. | Bild: Valérie Chételat
Das Problem Privatsphäre
An ihre Grenzen gelangt die Forderung nach Transparenz der Forschung, wenn offengelegte Informationen genutzt werden, um den Ruf von Wissenschaftlern zu beschädigen. Klimaforscher – gerade im angelsächsischen Raum – können ein Lied von enervierenden Anfragen zur Freigabe von Daten singen, etwa gemäss dem "Freedom of Information Act", einem Gesetz von 1967. Oft wurden die gesammelten Informationen anschliessend dazu genutzt, um die Mainstream-Klimaforschung als fragwürdig hinzustellen. Michael Mann von der Pennsylvania State University dürfte das prominenteste Opfer solcher Aktivisten sein.
Wie weit Forscher mit der Offenlegung ihrer Arbeit gehen sollen, lässt sich also nicht so einfach entscheiden. Ein zu grosser Transparenzdruck kann auch ein unerwünschtes Resultat haben: Innere Zensur kann etwa zu konformistischem Verhalten führen. Das aber würde den Erfolgsaussichten von Open Science zuwiderlaufen.
Zu einem besonders schwerwiegenden Problem wird die Privatsphäre, wenn es um die Rechte Dritter geht, zum Beispiel, wenn Patientendaten aus klinischen oder genetischen Studien für andere Mediziner zugänglich gemacht werden sollen. Die Folgen können richtig ärgerlich sein: Ärzte mit Patienten, die an sehr seltenen Krankheiten leiden, standen bis anhin oft vor dem Problem, konkrete Vergleichsfälle zu finden, um sich bei der Therapie daran zu orientieren. Der Datenschutz war im Weg.
Aber auch für so schwierige Fälle gibt es Lösungen. 2013 wurde zum Beispiel die "Global Alliance for Genetic Health" gegründet. Dieser weltweite Verbund von mehr als 380 Institutionen entwickelt raffinierte Verfahren, damit Patientendaten auf freiwilliger Basis sicher und effektiv geteilt werden können. Dazu wurden ein fein abgestuftes Modell von Einwilligungen zur Datenfreigabe durch Patienten sowie Algorithmen für den Datenzugriff entwickelt. Am Ende soll der Austausch der Patientendaten vor allem der Erforschung von seltenen Krankheiten, Infektionskrankheiten und Krebs dienen.
Um den Kulturwandel hin zu Open Science trotz aller Hindernisse zu realisieren, ist also noch ein beträchtlicher Aufwand nötig.
Sven Titz ist Wissenschaftsjournalist in Berlin.